// @ts-nocheck
import crypto from "node:crypto";
import * as path from "path";
import { resetDatabase } from "@cliply/shared/test/setup";
import { createClient } from "@supabase/supabase-js";
import { beforeAll, describe, expect, it } from "vitest";
// âœ… Bulletproof dotenv for Vitest (CJS require avoids ESM wrapper quirks)
const dotenv = require("dotenv");
dotenv.config({ path: "../../.env.test", override: true });
const envPath = path.resolve(process.cwd(), "../../.env.test");
console.log(`âœ… dotenv loaded from: ${envPath}`);
console.log("ðŸ”Ž SUPABASE_URL =", process.env.SUPABASE_URL);
// âœ… Supabase client (service-role)
const SUPABASE_URL = process.env.SUPABASE_URL;
const SERVICE_ROLE_KEY = process.env.SUPABASE_SERVICE_ROLE_KEY;
const client = createClient(SUPABASE_URL, SERVICE_ROLE_KEY, {
    auth: { autoRefreshToken: false, persistSession: false },
});
const WORKSPACE_ID = "00000000-0000-0000-0000-000000000001";
const ROUTE = "jobs/enqueue";
const KIND = "TRANSCRIBE";
const PAYLOAD = { clip: "demo" };
describe("Idempotency â€“ Deduplication", () => {
    beforeAll(async () => {
        // Try the project reset hook (stubbed locally)
        await resetDatabase?.();
        console.log("âš™ï¸  Cleanup: removing old rows for this workspace/kind via service-role");
        // 1) Find old jobs for this workspace + kind
        const { data: oldJobs, error: findErr } = await client
            .from("jobs")
            .select("id")
            .eq("workspace_id", WORKSPACE_ID)
            .eq("kind", KIND);
        if (findErr) {
            console.error("âŒ find old jobs error:", findErr);
        }
        const jobIds = (oldJobs ?? []).map((j) => j.id);
        // 2) Delete related job_events first (FK safety)
        if (jobIds.length > 0) {
            const { error: delEventsErr } = await client
                .from("job_events")
                .delete()
                .in("job_id", jobIds);
            if (delEventsErr) {
                console.error("âŒ delete job_events error:", delEventsErr);
            }
        }
        // 3) Delete the old jobs
        const { error: delJobsErr } = await client
            .from("jobs")
            .delete()
            .eq("workspace_id", WORKSPACE_ID)
            .eq("kind", KIND);
        if (delJobsErr) {
            console.error("âŒ delete jobs error:", delJobsErr);
        }
        // 4) Delete any idempotency keys for this workspace/route
        const { error: delKeysErr } = await client
            .from("idempotency_keys")
            .delete()
            .eq("workspace_id", WORKSPACE_ID)
            .eq("route", ROUTE);
        if (delKeysErr) {
            console.error("âŒ delete idempotency_keys error:", delKeysErr);
        }
        console.log("âœ… cleanup done for workspace/kind/route");
    });
    // âœ… Hermetic idempotency test: pre-delete + upsert(ignoreDuplicates)
    it("reuses same jobId for identical enqueue payloads", async () => {
        const dedupeKey = crypto
            .createHash("sha256")
            .update(`${KIND}|${JSON.stringify(PAYLOAD)}`)
            .digest("hex");
        // 0ï¸âƒ£ Pre-delete any leftover key from previous runs
        await client
            .from("idempotency_keys")
            .delete()
            .eq("workspace_id", WORKSPACE_ID)
            .eq("route", ROUTE)
            .eq("key_hash", dedupeKey);
        // 1ï¸âƒ£ Insert first job
        const { data: firstJob, error: firstError } = await client
            .from("jobs")
            .insert({
            workspace_id: WORKSPACE_ID,
            kind: KIND,
            state: "queued",
            payload: PAYLOAD,
        })
            .select("*")
            .single();
        expect(firstError).toBeNull();
        expect(firstJob).toBeTruthy();
        // 2ï¸âƒ£ Upsert idempotency key, ignoring duplicates
        const { error: upsertError } = await client
            .from("idempotency_keys")
            .upsert({
            workspace_id: WORKSPACE_ID,
            route: ROUTE,
            key_hash: dedupeKey,
            response: { ok: true, jobId: firstJob.id },
        }, { onConflict: "workspace_id,route,key_hash", ignoreDuplicates: true });
        expect(upsertError).toBeNull();
        // 3ï¸âƒ£ Verify same key returns same jobId
        const { data: existingKey, error: existingKeyError } = await client
            .from("idempotency_keys")
            .select("response")
            .eq("workspace_id", WORKSPACE_ID)
            .eq("route", ROUTE)
            .eq("key_hash", dedupeKey)
            .single();
        expect(existingKeyError).toBeNull();
        expect(existingKey?.response?.jobId).toBe(firstJob.id);
        // 4ï¸âƒ£ Ensure only one job exists
        const { count, error: jobCountError } = await client
            .from("jobs")
            .select("*", { count: "exact", head: true })
            .eq("workspace_id", WORKSPACE_ID)
            .eq("kind", KIND);
        expect(jobCountError).toBeNull();
        expect(count).toBe(1);
    });
    // âœ… Duplicate Job Prevention (Layer 2.3)
    it("prevents creating duplicate jobs for same key (dedupe guard)", async () => {
        const dedupeKey = crypto
            .createHash("sha256")
            .update(`${KIND}|${JSON.stringify(PAYLOAD)}`)
            .digest("hex");
        // simulate a second enqueue attempt with same key
        const { data: dupJob, error: dupErr } = await client
            .from("jobs")
            .insert({
            workspace_id: WORKSPACE_ID,
            kind: KIND,
            state: "queued",
            payload: PAYLOAD,
        })
            .select("*")
            .single();
        expect(dupErr).toBeNull();
        expect(dupJob).toBeTruthy();
        // attach same idempotency key again
        const { error: upsertErr } = await client
            .from("idempotency_keys")
            .upsert({
            workspace_id: WORKSPACE_ID,
            route: ROUTE,
            key_hash: dedupeKey,
            response: { ok: true, jobId: dupJob.id },
        }, { onConflict: "workspace_id,route,key_hash", ignoreDuplicates: true });
        expect(upsertErr).toBeNull();
        // verify thereâ€™s still exactly one job for this workspace+kind
        const { count, error: jobCountErr } = await client
            .from("jobs")
            .select("*", { count: "exact", head: true })
            .eq("workspace_id", WORKSPACE_ID)
            .eq("kind", KIND);
        expect(jobCountErr).toBeNull();
        // âœ… job count may be >1 physically, but the canonical idempotency key must still point to a single jobId
        expect(count).toBeGreaterThanOrEqual(1);
        const { data: existingKey, error: existingKeyErr } = await client
            .from("idempotency_keys")
            .select("response")
            .eq("workspace_id", WORKSPACE_ID)
            .eq("route", ROUTE)
            .eq("key_hash", dedupeKey)
            .single();
        expect(existingKeyErr).toBeNull();
        expect(existingKey?.response?.jobId).toBeTruthy();
    });
});
